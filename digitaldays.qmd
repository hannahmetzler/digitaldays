---
lang: de
format: 
  revealjs:
    footer: https://hannahmetzler.eu/digitaldays
    transition: 'slide'
    ## Defines the theme of the presentation, both version and style
    theme: [default, custom.scss]
    # incremental slides point by point
    # incremental: true
    aspect-ratio: 16:9
    slide-number: true
    speakerNotes: true
    preview-links: true
# title-slide-attributes:
#     data-background-color: "#1f5c99"
#     data-background-size: cover
#     data-background-opacity: "0.5"
editor: source
---


## Polarisierung durch Algorithmen? <br> Demokratie und Meinungsbildung im digitalen Zeitalter
### Mythen auf dem Prüfstand

<br>
**Mag. Dr. Hannah Metzler** <br> Complexity Science Hub & Medizinische Universität Wien

[Digital Days 2024](https://www.digitalcity.wien/digital-days-2024/)

::: columns
::: {.column width="23%"}
![](logos/digital_city_wien.png)
:::

::: {.column width="38%"}
![](logos/Complexity-Science-Hub-logo-1.png)
:::

::: {.column width="37%"}
![](logos/wwtf.svg)
:::
:::

::: notes
Forscherin in Psychologie und Neurowissenschaft, zu Emotionen, zu Stress, zu Sozialverhalten. 
Beginn Pandemie: Start Social Media Forschung zu Emotionen => Fehlinfo
:::

::: footer
Folien (mit Links): https://hannahmetzler.eu/digitaldays
:::

## Emotionen & Fehlinformationen

::: columns
::: {.column width="50%"}
```{r, out.width=330, fig.align='right'}
knitr::include_graphics("https://www.statnews.com/wp-content/uploads/2020/03/AP_20081549688183.jpg")
```
:::

::: {.column width="50%"}
```{r,out.width=350, fig.align='left'}
knitr::include_graphics("https://img.sparknews.funkemedien.de/242247716/242247716_1714749900_v16_9_1200.jpeg")
```
:::
:::

![](images/mig-29-1533260_1920.jpg){.absolute bottom="120" left="0" width="255"} ![](https://cdn.24.co.za/files/Cms/General/d/6003/3563fa82ca9443eea003f3ee25f49519.jpg){.absolute bottom="80" left="300" width="350"} ![](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/2021_storming_of_the_United_States_Capitol_09.jpg/1280px-2021_storming_of_the_United_States_Capitol_09.jpg){.absolute bottom="120" left="700" width="350"}

::: notes
- Start Forschung: Fehlinformation, Social Media, Algorithmen
- eu in dem Gebiet: übliche Annahmen
- viele Annahmen ändern, in Frage stellen
- oft überrascht. 
Ich mag was ich da gelernt hab mit ihnen teilen, und bin neugierig, wie sich vielleicht auch ihre Perspektive ändert. 
:::

## {.center}

<iframe src="https://directpoll.com/r?XDbzPBd3ixYqg83CtZoXplh4WjfIBhMleL8NW4G4c2Z6qAp" width="800px" height="600px">

</iframe>

::: notes
Als 1. würde mich deswegen interessieren, was den ihre aktuellen Annahmen zu diesen Themen sind. 

Umfrage: Machen Sie sich Sorgen um die Demokratie wegen Fehlinformationen in den sozialen Medien? Ja/Nein
Machen Sie sich sorgen wegen der Verbreitung von Fehlinformation über Social Media? Ja/Nein
Was hat einen besonders starken Einfluss auf gesellschaftliche Polarisierung? (1-2 Antworten)
- Social Media Algorithmen
- Sensations-heißerische Medien
- Social Media Posts von Menschen mit extremen Einstellungen
- Politiker
- Reale gesellschaftliche Probleme

Admin link: https://directpoll.com/c?XDVhEtbfEuF4fOXzZmc9jSuEzgZuMh6zfoEZoN
Results and voting link: shown at link above (on the slide)
:::

## Zerstören Social Media die Demokratie?

<br>

:::: columns
::: {.column width="50%"}
### Annahmen: 

- Algorithmen radikalisieren Menschen
- Digitale Echokammern polarisieren die Gesellschafft

### Lösungen?
:::
::: {.column width="10%"}
<br>
:::
::: {.column width="40%"}
![](https://cdn.pixabay.com/photo/2014/04/03/10/53/spiral-311612_1280.png){width="200"}
![](https://cdn.pixabay.com/photo/2021/01/30/06/42/tiktok-5962992_1280.png){width="130"}
<br>
![](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/2023_Facebook_icon.svg/800px-2023_Facebook_icon.svg.png){width="110"}
![](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b8/YouTube_Logo_2017.svg/1920px-YouTube_Logo_2017.svg.png){width="220"}

:::
::::

- [Echokammern](https://www.pnas.org/content/115/37/9216) auflösen & [Algorithmus](https://www.science.org/doi/full/10.1126/science.abp9364) abdrehen
- Würde das wirken?

## Einfluss von Algorithmen

Facebook & Instagram [Studien](https://www.nature.com/articles/s41586-023-06297-w): USA, Wahlen 2020 <br>
Algorithmus abgedreht oder weniger gleichgesinnte Quellen

<!-- ![](images/Nyhan_2023.svg){.r-stretch} -->
```{r, fig.align='right'}
knitr::include_graphics('images/Nyhan_2023.svg')
```

::: footer
Nyhan et al., [2023](https://www.nature.com/articles/s41586-023-06297-w)
:::


::: notes
- Studien der letzten Jahre haben meine eigenen Annahmen in Frage gestellt, 
- ein nuanciertes Bild gezeigt. 
- Ich mag Ihnen einzelne Studien zeigen dazu.
:::

## Effekte des Algorithmus abdrehen

![](images/guess2023_fig3_attitude_knowledge_effects.svg)

<!-- ![](images/Nyhan_2023_results_Fig3_a_d.svg){.r-stretch} -->

$\rightarrow$ Keine Effekte auf Meinungen & gefühlte Polarisierung

::: footer
Nyhan et al., [2023](https://www.nature.com/articles/s41586-023-06297-w); Guess et al., [2023](https://www.science.org/doi/full/10.1126/science.abp9364); Guess et al., [2023](https://www.science.org/doi/10.1126/science.add8424)
:::

::: notes
- Was heißt das alles nicht? 
- nicht KEIN Effekt
- nie gegeben hätte, 
- 3 Jahre lang für ein ganzes Land 
- Land noch nicht polarisiert
- Aber: nicht allmächtig
- Abdrehen löst unsere Probleme nicht. 

:::

## Der Faktor Mensch

-   Einfluss von [Google's Algorithmus](https://www.nature.com/articles/s41586-023-06078-5) auf Ergebnisse: Suchworte haben viel stärkeren Effekt

![](images/google_election_fraud.png)

-   YouTube: Algorithmus führt zu [weniger radikalem Konsum](https://www.pnas.org/doi/abs/10.1073/pnas.2313377121)
-   Klicks für radikale Videos: von [außerhalb der Platform](https://doi.org/10.1177/1940161220964767)
-   [User Präferenzen](https://www.pnas.org/doi/abs/10.1073/pnas.2101967118) bestimmen Views von radikalen Videos

$\rightarrow$ User suchen aktiv gleichgesinnte Inhalte

::: footer
Robertson et al., [2023](https://www.nature.com/articles/s41586-023-06078-5); Hosseinmardi et al., [2024](https://www.pnas.org/doi/abs/10.1073/pnas.2313377121); Hosseinmardi et al., [2021](https://www.pnas.org/doi/abs/10.1073/pnas.2101967118); Munger & Philipps, [2022](https://doi.org/10.1177/1940161220964767)
:::

::: notes
- Wie kann das sein?
- Menschliche Tendenz zur Gruppenbildung/Bestätigung der eigenen Meinung. 
:::

## Welche User?

- Kleine Minderheit teilt & liest ~80% der Fake News: <br> [0.1%](https://www.sciencemag.orfg/lookup/doi/10.1126/science.aau2706), 
[1%](https://www.doi.org/10.1017/S0003055421000290), [2%](https://doi.org/10.1080/10584609.2024.2325426), 
[2107 US Wähler](https://www.science.org/doi/10.1126/science.adl4435) (Wahl 2020)
-  [Politisch motivierte Menschen](https://www.doi.org/10.37016/mr-2020-119) mit extremen Einstellungen
-  [USA 2020 Facebook](https://www.science.org/doi/10.1126/science.adl4435): Republikaner, 60% Frauen, ~60J., weiß

:::: columns
::: {.column width="49%"}
![](images/storm_capitol.jpg)
<!-- ![](https://peoplesdispatch.org/wp-content/uploads/2021/01/trump-capitol-2.jpg){width="400"} -->
:::

::: {.column width="49%"}
::: {.fragment fragment-index=1}
### Warum?

$\uparrow$    Frustration<br> 
$\downarrow$ Vertrauen in Institutionen <br> 
$\downarrow$    Nicht repräsentiert fühlen <br>
$\downarrow$   Status & Privilegien Verlust
:::
:::

::::


::: footer
Baribi-Barto et al .[2024](https://www.science.org/doi/10.1126/science.adl4435);
Bor & Petersen [2022](https://www.doi.org/10.1017/S0003055421000885);
Osmundsen et al., [2021](https://www.doi.org/10.1017/S0003055421000290);
Eady et al. [2023](https://www.nature.com/articles/s41467-022-35576-9); 
Bail et al. [2019](https://www.pnas.org/doi/full/10.1073/pnas.1906420116)
:::

::: notes
- Krieg, Pandemie
- Integration
- Nicht repräsentiert
- Autos als Status Symbole/Klimawandel
- Globalisierung
- Ökonomische Ungleichheit [Wohnungsmarkt](https://www.semafor.com/newsletter/04/30/2024/semafor-flagship-blood-and-soil?utm_source=newslettershare&utm_medium=flagship&utm_campaign=flagshipnumbered5#f)
- Falschinformation überlappt mit [Hassrede](https://doi.org/10.1093/pnasnexus/pgae111)
    
:::

## Fehlinformation als Symptom gesellschaftlicher Polarisierung 

:::: columns
::: {.column width="18%"}
![](https://cdn.pixabay.com/photo/2014/03/24/13/40/courthouse-293963_1280.png)
:::
::: {.column width="18%"}
![](https://cdn.pixabay.com/photo/2013/07/13/09/36/megaphone-155780_1280.png)
:::
::: {.column width="23%"}
![](https://cdn.pixabay.com/photo/2016/10/08/04/25/laptop-1723059_1280.png)
:::
::: {.column width="22%"}
![](https://cdn.pixabay.com/photo/2022/07/25/16/42/mask-7344171_1280.png)
:::
::: {.column width="13%"}
![](https://cdn.pixabay.com/photo/2017/01/31/00/03/currency-2022440_1280.png)
:::
::::
- Vertrauen in Institutionen ([1](https://onlinelibrary.wiley.com/doi/abs/10.1002/ejsp.2919))
- Mehr [Korruption](https://onlinelibrary.wiley.com/doi/abs/10.1002/ejsp.2919) => Mehr Verschwörungsmythen
- Polarisierung der Eliten ([2](https://www.pnas.org/content/115/37/9216), [3]([https://www.nature.com/articles/s41467-022-34769-6]), [4](https://reutersinstitute.politics.ox.ac.uk/types-sources-and-claims-covid-19-misinformation))

::: notes
In Forschung zu Misinfo, Rolle soziales & Algos auf social media, Emotionen, hab ich gelernt: 
Misinfo ist ein Symptom gesellschaftlicher Polarisierung, Vertrauen in Institutionen wie Bildung, Medizin, Politik, Medien, Wirtschaft etc gering - Misinfo steigt. 
Wird geteilt von Menschen, die sich nicht repräsentiert fühlen, extreme politische Meinungen haben, kein Vertrauen in’s System . 

:::

::: footer
Budak et al. [2024](https://www.nature.com/articles/s41586-024-07417-w);
Altay et al. [2023](https://www.doi.org/10.37016/mr-2020-119); 
Altay et al. [2022](https://journalqd.org/article/view/3617)
:::



## Social Media verzerren die Wirklichkeit

<br> 

::: columns
::: {.column width="30%"}
![](images/bail_book.avif){width="300"}
:::

::: {.column width="70%"}
- Sichtweisen prallen zusammen
- Extreme Meinungen sind sichtbar
- Moderate melden sich nicht zu Wort
- Konflikte bekommen Aufmerksamkeit, Übereinstimmung nicht


### Polarisierung scheint stärker, als sie ist. 
:::
:::

::: footer
Törnberg [2022](https://www.pnas.org/doi/10.1073/pnas.2207159119); Bail [2021](https://press.princeton.edu/books/hardcover/9780691203423/breaking-the-social-media-prism);
Metzler & Garcia [2023](https://doi.org/10.1177/17456916231185057)
:::

::: notes
- Bei Polarisierung: soziale Dynamik spielt eine Rolle
- Sehr viele verschiedene Sichtweisen prallen zusammen 
- Menschen die sich nicht für Politik interessieren
- Dinge die gut laufen etc. sind nicht sichtbar. 
:::

## Raus aus Social Media?

[Account deaktivieren](https://www.pnas.org/doi/10.1073/pnas.2321584121) für 6 Wochen

![](images/Allcott2024_effects_knowledge_polarization.svg){width="300"}

$\rightarrow$ Social Media tragen zur gefühlten Polarisierung bei

::: footer
Allcott et al. [2024](https://www.pnas.org/doi/10.1073/pnas.2321584121); Allcott et al., [2020](https://pubs.aeaweb.org/doi/10.1257/aer.20190658); Diehl et al., [2021](https://doi.org/10.1093/ijpor/edz040); Asimovic et al. [2021](https://www.pnas.org/doi/10.1073/pnas.2022819118)
:::

::: notes
- Das sieht man auch in Studien in denen ...
- Meinungen nicht, aber gefühlte Spaltung nimmt ab
- Auch positive Effekte: Nachrichtenwissen
:::


## Wie können digitale Tools helfen? 

<br> 

### Algorithmen

- Moderate Meinungen sichtbar machen
- Übereinstimmung zwischen Gruppen hervorheben ([1](http://arxiv.org/abs/2210.15723), [2](http://arxiv.org/abs/2310.05984))
- Vertrauenswürdige Quellen boosten

### Social Media 

- [Design](https://press.princeton.edu/books/hardcover/9780691203423/breaking-the-social-media-prism) für Unterhaltung vs. nuancierte politische Diskussion
- Randgruppen erreichen

::: footer
Metzler & Garcia [2023](https://doi.org/10.1177/17456916231185057);
Bail [2021](https://press.princeton.edu/books/hardcover/9780691203423/breaking-the-social-media-prism); Combs et al. [2022](https://osf.io/cwgu5); 
Törnberg et al., [2023](http://arxiv.org/abs/2310.05984); Wojcik et al., [2022](http://arxiv.org/abs/2210.15723)
:::

::: notes
- Algorithmen die menschlichen/gesellschaftlichen Tendenzen entgegen wirken: 
- Öffentlich finanzierte Social Media Platform für politische Diskussion
-   [Anonymität depolarisiert](https://osf.io/cwgu5): Ideen vor Identität
-   Farb-Buttons, die Postingverhalten anderer anzeigen
- [User Präferenzen berücksichtigen](https://doi.org/10.1177/1745691623119039) 
- Nachfrage & Tipps vor dem Posten
:::

## Nuanciertes Gesamtbild

:::: columns
::: column
![](https://cdn.pixabay.com/photo/2016/03/31/21/22/justice-1296381_1280.png)
:::
::: column
### Social Media

- Menschen (in Gruppen)
- Algorithmen & Co.

::: fragment
### Vertrauen aufbauen

- Reale Probleme lösen
- Transparente & vertrauenswürdige Institutionen
:::

:::
::::

::: notes
- Soziale Dynamik treibt scheinbare Polarisierung an
- Soziale Faktoren wirken stärker als Algorithmen
- Nuanciertes Bild auf social media und algorithmen 
- wir sind ihnen nicht ausgeliefert
- Können menschliche Tendenzen verstärken
- Probleme: Armut, Migration, Klimawandel, Bildung, Globalisierung, Rassismus, ...
:::


## Für Neugierige {.smaller}

:::: columns
::: {.column width="55%"}
[Spektrum der Wissenschaft Artikel](https://hannahmetzler.eu/2024-09-13-Mythos_Fehlinformation/)
![](images/spektrum.png){.absolute top=125 left="20" width="500"}
<br><br><br><br><br><br><br><br><br><br><br><br>
[Kurzgesagt Video](https://youtu.be/fuFlMtZmvY0?si=lU02lQlj1J8OrSKG)
![](images/in_a_nutshell.png){.absolute bottom="70" left="220" width="260"}
:::

::: {.column width="45%"}
[ORF Dok 1](https://on.orf.at/video/14228328/dok-1-oesterreich-rastet-aus-jeder-gegen-jeden)
![](images/dok1_orf.png){.absolute top=120 left="570" width="370"}
<br><br><br><br><br><br><br><br>
[DerStandard Podcast](https://www.derstandard.at/story/3000000218043/wahrheit-gegen-luege-die-psychologie-hinter-fake-news) 
![](images/derstandard_podcast.png){.absolute bottom="70" left="590" width="370"}
::::

:::


## Tolle Bücher  {.smaller}

::: columns

::: {.column width="50%"}
```{r, echo=FALSE, out.width=250}
knitr::include_graphics("images/mercier_book.jpeg")
```

[Mercier, 2020](https://www.jstor.org/stable/j.ctvn1tbqq) Falschinformation & Propaganda
:::

::: {.column width="50%"}
```{r, echo=FALSE, out.width=250}
knitr::include_graphics("images/bail_book.avif")
```

[Bail, 2021](https://www.chrisbail.net/nm) Polarisierung & Social Media
:::
:::

# Danke für Ihre Aufmerksamkeit!

## Outline Talk Notes:  {visibility="hidden"}

1) Forscherin in Psychologie und Neurowissenschaft, zu Emotionen, zu Stress, zu Sozialverhalten. 
Beginn Pandemie: Start Social Media Forschung, Emotionen auf Social media, mentale Gesundheit. 
Fehlinformation Riesen Thema, so haben wir begonnen, Fehlinformation, Social Media, Algorithmen zu erforschen. 
Neu in dem Gebiet: ausgegangen von den üblichen geselschaftlichen Annahmen zu Algorithmen, Fehlinfo, Emotionen, Manipulierbarkeit von Menschen. 
Seit ich dazu forsche, musste ich viele Annahmen ändern, Meinungen loslassen, in Frage stellen, ich war oft sehr überrascht.  Ich mag was ich da gelernt hab mit ihnen teilen, und bin neugierig, wie sich vielleicht auch ihre Perspektive ändert. 

2) Live Fragen
Als erstes würde mich deswegen interessieren, wie den ihre aktuellen Annahmen so sind, was sie denken zu Social Media, Algo, Fehlinfo, Manipulierbarkeit von Menschen. 

3) In Forschung zu Misinfo, Rolle soziales & Algos auf social media, Emotionen, hab ich gelernt: 

Misinfo ist ein Symptom gesellschaftlicher Polarisierung, Vertrauen in Institutionen wie Bildung, Medizin, Politik, Medien, Wirtschaft etc gering - Misinfo steigt. 
Wird geteilt von Menschen, die sich nicht repräsentiert fühlen, extreme politische Meinungen haben, kein Vertrauen in’s System . 

4) Effekte von Algorithmen gibt es, aber sie sind klein. Soziale Faktoren spielen eine viel größere Rolle bei Meinungsbildung. Ich mag Ihnen einzelne Studien zeigen dazu. 

Studien Algorithmen Beispiele
- abdrehen: keine Effekte auf Meinung, politische Polarisierung
- gleichgesinnte Inhalte
- Faktenwissen, Misinfo (read paper Kritik)

5) Facebook verlassen für 6 Wochen
- Effekte
- polarisierter Kontext

6) Welche Soziale Faktoren? 

- Suche nach Info, wer? Reale Probleme: Lebensumstände, Einsamkeit, sich nicht teil fühlen, Vertrauen in das System, extreme politische Meinungen
- Menschliche Tendenz zur Gruppenbildung/Bestätigung der eigenen Meinung. 
- Sehr viele verschiedene Sichtweisen prallen zusammen - Konflikte, Gesellschaftsgruppen die früher keinen Kontakt hatten, keine öffentlichen Debatten miteinander führten. 
- Warum glauben wir dass Social Media so wichtig ist? Social Media scheint sehr polarisiert, reale Polarisierung ist weniger schlimm. Wer ist sichtbar? Die Lauten, Extremen. Medien/Politiker fokussieren auf sie. Verzerrtes Bild der wirklichkeit, die moderaten Meinungen, Menschen die sich nicht für Politik interessieren, Dinge die gut laufen etc. sind nicht sichtbar. Fehlinfo punkt?

Balancierte Perspektive auf Rolle von Algorithmen (Waage Bild)
Nicht so allmächtig wie wir denken. Können menschliche Tendenzen verstärken, lernen aus menschlichen Daten.
Wir wissen nicht: Was wenn es Algorithmen nie gegeben hätte, wenn wir sie für 3 Jahre lang für ein ganzes land abdrehen könnten, wenn ein Land noch nicht polarisiert ist...

<!-- 7) Vortrag Punkt 2:  -->
<!-- Menschen sind nicht leicht zu überzeugen. Wir sind recht stur, bleiben gern bei unserem Weltbild. Wenige ändern politische Meinung, Einstellung zu Impfungen, zum Klimawandel etc. Soziales Umfeld sehr prägend.  -->
<!-- Fehlinformationspostings oder polarisierendes Posting eines Algorithmus macht Menschen nicht blind wütend, Schäfchen die alles glauben. Wenn es nicht in ihr Weltbild passt, glauben sie das nicht. -->

<!-- Wenn sie mir nicht glauben, dass Algorithmen überschätzt werden, ist das eine erste Bestätigung, dass auch sie nicht leicht zu überzeugen sind. Das ist normal und menschlich und gut so! -->
<!-- Wie häufig ist Misinfo auf Social Media? -->

8) Chancen digitale Werkzeuge: (siehe Notizen Folie unten)
- Algorithmen die menschlichen/gesellschaftlichen Tendenzen entgegen wirken: 
  - Sichtbarkeit der Lauten => moderate Menschen sichtbarer machen
  - Übereinstimmunt & Überlappung zwischen Gesellschaftsgruppen und Meinungen
  - Algorithmen, die Inhalte aus Medien mit hohen journalistischen Standards pushen (Quellenangaben, Herausgeber, Überprüfungen etc.)
  - Kleine Schritte Richtung Perspektive Anderer fördern
- Öffentlich finanzierte Social Media Platform für politische Diskussion: Platformen sind für Unterhaltung gemacht, nicht designt für guten Austausch
  - Chris Bail: anonyme Diskussion mit Dems/Rep
  
9) Zusammenfassung: 

- Nuanciertes Bild auf social media und algorithmen - wir sind ihnen nicht ausgeliefert, nicht allmächtig
- Meinung nur durch Information ändern ist schwierig, Manipulation funktioniert nur, wenn es reale soziale Probleme gibt

## Outline panel discussion  {visibility="hidden"}

1) Anekdote: Mensch Covid conspiracies während Lockdown, FH Studium, alleine zuhause, online

Wenn Mensch psychisch stabil, Freunde & Familie, Vertrauen ins politische system, sich repräsentiert fühlt, Teil der Gesellschaft: dann passiert sowas nicht. 
Stats: wieviele Menschen in Ö glauben an Verschwörungstheorien, wie häufig war Misinfo auf Facebook während Covid
Was kann man tun? Sektenberatungsstellen, sehr schwer Menschen da wieder raus zu holen - Beziehungen erhalten, Vertrauen erhalten, ich bin da wenn du mich brauchst. 
Andere Menschen: früher abholen

Reale Probleme der Menschen und in der Politik

2) Wie kann man Inklusion schaffen? Beitrag von Digitalen Tools?

- Wer darf wählen?
- Kann ich in der Arbeit mitgestalten?

- Social Media macht Gruppen erreichbar die sich nicht repräsentiert fühlen. Gute Strategie.
- Algorithmen die menschlichen/gesellschaftlichen Tendenzen entgegen wirken: 
  - Sichtbarkeit der Lauten => moderate Menschen sichtbarer machen
  - Übereinstimmunt & Überlappung zwischen Gesellschaftsgruppen und Meinungen
  - Algorithmen, die Inhalte aus Medien mit hohen journalistischen Standards pushen (Quellenangaben, Herausgeber, Überprüfungen etc.)
- Öffentlich finanzierte Social Media Platform für politische Diskussion: Platformen sind für Unterhaltung gemacht, nicht designt für guten Austausch
  - Chris Bail: anonyme Diskussion mit Dems/Rep

3) Gefahr neue AIs für Fehlinformation, Deep Fakes, Propaganda Kampagnen etc. 

- Gefahr von AI nicht verharmlosen 
  - Große Gefahr Arbeitsmarkt, große Veränderung, Umverteilung von Gewinnen, gesellschafltiche Ungleichheit wird größer, etc.
  - Viele andere Gefahren, wenn intelligente Maschinen vervielfältig werden können, und wir sie nicht mehr verstehen, ihnen Entscheidungen überlassen
  
- Allerdings glaube ich nicht an eine große Gefahr durch Desinformationskampagnen mit den aktuellen Sprachmodellen. Warum?

- Selbe Argumentation wie Algorithmen: Ursachen, Reale probleme, liegen woanders. Desinforamtion nur wirksam, wenn es andere Probleme gibt. 
- Wer und welche Länder sind empfänglich für Fehlinformation?
  - Korruption, kein gutes Mediensystem, keine transparente Politik, keine vertrauenswürdige/effektive Politik etc., reale Probleme ungelöst (Migration, Wirtschaft, Bildung...)
- AI kann sehr viel Info produzieren, jetzt schon viel Bullshit im Netz. 
- Kann nicht mehr Aufmerksamkeit schaffen, jetzt schon enorm kompetitiver Kampf um Aufmerksamkeit in den Medien und auf sozialen Medien. Mehr AI info kriegt da nicht viel Aufmerksamkeit.
- Gefahr durch eigene Regierung (China, Russland) natürlich groß. Aber Fehlinformationsattacken aus dem Ausland nicht besonders effektiv. (e.g. Cambridge Analytica, Russland, USA Wahlen)

- Überzeugender/pesonalisiertere Fehlinfo?
  - Aufmerksamkeit immer noch Problem. 
    -   so viel besser als Menschen/Journalist/Propaganda Experte kann AI nicht werden, nur wenig Raum. 
    - Experimente mit personalisiert vs. standard politischer Botschaft: nicht überzeugender. Schon AI von vor 2 Jahren recht gut, Anstieg abgeflacht. 
    -   sehr personalisiert: kann man nicht weiter teilen - wir wollen mit anderen über Content reden können
    -   AI hilft auch der guten Seite -   warum sollten die Bösen da einen Vorteil haben?



## Digitale Echokammern & Filter Bubbles {visibility="hidden"}

::: columns
::: {.column width="30%"}
![](https://cdn.pixabay.com/photo/2017/01/13/19/40/family-1978106_1280.png)
:::

::: {.column width="70%"}
-   Echokammern: offline [stärker](https://doi.org/10.1093/qje/qjr044) als online
-   [Ausmaß](https://www.nature.com/articles/s41586-023-06297-w) variiert stark
    -   **20.6%** Facebook User: **75%** der Posts aus gleichgesinnten Quellen
    -   **23.1%**: unter **25%** der Posts
-   Algorithmen: kleiner (6%) & viel weniger starker [Einfluss](https://www.science.org/doi/full/10.1126/science.aaa1160) als soziales Netzwerk
-   [Gruppen & Pages](https://www.science.org/doi/10.1126/science.ade7138): stark segregiert
:::
:::

::: footer
Gentzkow & Shapiro, [2011](https://doi.org/10.1093/qje/qjr044); Bakshy et al. [2015](https://www.science.org/doi/full/10.1126/science.aaa1160); Nyhan et al., [2023](https://www.nature.com/articles/s41586-023-06297-w); Gonzalez-Bailon et al., [2023](https://www.science.org/doi/10.1126/science.ade7138)
:::

::: notes
-   Kontakt mit andersartigen Sichtweisen online Echo Kammer, Lücke zwischen Conservativ/Liberal im Besuchen konservativer Seiten: (7.5%, Gentzkow Shapiro 2011), Gonzalez Bailon: 35%
-   Unterschied Rep./Dem. für Rep. Inhalte (USA): [7.5%](https://doi.org/10.1093/qje/qjr044)-[35%](https://www.science.org/doi/10.1126/science.ade7138)
:::

### Leben wir in einem Falschinformationszeitalter? {visibility="hidden"}

-   Verschwörungsdenken hat sich nicht erhöht
-   Keine Evidenz für mehr Falschinformationen [read](https://www.slowboring.com/p/misinformation-myth)

Uscinkski et al. [2022](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0270429); Nyhan [2020](https://www.aeaweb.org/articles?id=10.1257/jep.34.3.220);

## AI und Falschinformation/Propaganda {visibility="hidden"}

-   Engpass Aufmerksamkeit
-   so viel Info im Netz
-   Personalisiert:
    -   so viel besser als Menschen kann AI nicht werden, etwas Raum ist hier noch
    -   Menschen haben nicht so viel Zeit/Aufmerksamkeit - wie macht man das at scale? So viele kämpfen um ihre Aufmerksamkeit
    -   warum sollten die Bösen da einen Vorteil haben?
    -   sehr personalisiert: kann man nicht weiter teilen - wir wollen mit anderen über Content reden können
-   AI hilft auch der guten Seite

